2019-04-03 14:52:21.514563: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-04-03 14:52:21.614713: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Loading corpus from /home/jake_miller/final/nlp-final-project/data
Begin corpus post-processing ...
Splitting corpus into training and test ...
Creating vocabulary from training set ...
Found 8379 unique words.
Building initial embedding matrix ...
(8381, 200)
loading pretrained vectors from glove.6B.200d.txt
Epoch 1/50
/home/jake_miller/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.

  1/633 [..............................] - ETA: 39:56 - loss: 3.5184 - acc: 0.0469
  2/633 [..............................] - ETA: 22:39 - loss: 6.8542 - acc: 0.0859
  3/633 [..............................] - ETA: 16:52 - loss: 8.5570 - acc: 0.1432
  4/633 [..............................] - ETA: 13:58 - loss: 9.8177 - acc: 0.1465
  5/633 [..............................] - ETA: 12:14 - loss: 10.3726 - acc: 0.1609
  6/633 [..............................] - ETA: 11:06 - loss: 10.9524 - acc: 0.1576
  7/633 [..............................] - ETA: 10:17 - loss: 11.2946 - acc: 0.1596
  8/633 [..............................] - ETA: 9:40 - loss: 11.5040 - acc: 0.1641 
  9/633 [..............................] - ETA: 9:11 - loss: 11.5270 - acc: 0.1762
 10/633 [..............................] - ETA: 8:47 - loss: 11.5454 - acc: 0.1859
 11/633 [..............................] - ETA: 8:27 - loss: 11.6863 - acc: 0.1861
 12/633 [..............................] - ETA: 8:10 - loss: 11.7933 - acc: 0.1868
 13/633 [..............................] - ETA: 7:54 - loss: 11.8838 - acc: 0.1875
 14/633 [..............................] - ETA: 7:38 - loss: 11.8265 - acc: 0.1964
 15/633 [..............................] - ETA: 7:24 - loss: 12.0035 - acc: 0.1901
 16/633 [..............................] - ETA: 7:12 - loss: 11.8907 - acc: 0.2012
 17/633 [..............................] - ETA: 7:01 - loss: 11.9246 - acc: 0.2027
 18/633 [..............................] - ETA: 6:51 - loss: 11.8498 - acc: 0.2105
 19/633 [..............................] - ETA: 6:43 - loss: 11.8159 - acc: 0.2155
 20/633 [..............................] - ETA: 6:36 - loss: 11.7666 - acc: 0.2211
 21/633 [..............................] - ETA: 6:31 - loss: 11.7640 - acc: 0.2236
 22/633 [>.............................] - ETA: 6:26 - loss: 11.7558 - acc: 0.2262
 23/633 [>.............................] - ETA: 6:21 - loss: 11.6772 - acc: 0.2330
 24/633 [>.............................] - ETA: 6:17 - loss: 11.6104 - acc: 0.2389
 25/633 [>.............................] - ETA: 6:13 - loss: 11.4633 - acc: 0.2497
 26/633 [>.............................] - ETA: 6:10 - loss: 11.4970 - acc: 0.2491
 27/633 [>.............................] - ETA: 6:05 - loss: 11.5982 - acc: 0.2442
 28/633 [>.............................] - ETA: 6:01 - loss: 11.6427 - acc: 0.2427
 29/633 [>.............................] - ETA: 5:56 - loss: 11.5626 - acc: 0.2489
 30/633 [>.............................] - ETA: 5:52 - loss: 11.5633 - acc: 0.2500
 31/633 [>.............................] - ETA: 5:49 - loss: 11.5721 - acc: 0.2505
 32/633 [>.............................] - ETA: 5:47 - loss: 11.6512 - acc: 0.2466
 33/633 [>.............................] - ETA: 5:45 - loss: 11.6759 - acc: 0.2460
 34/633 [>.............................] - ETA: 5:43 - loss: 11.7177 - acc: 0.2443
 35/633 [>.............................] - ETA: 5:41 - loss: 11.7679 - acc: 0.2420
 36/633 [>.............................] - ETA: 5:39 - loss: 11.7663 - acc: 0.2428
 37/633 [>.............................] - ETA: 5:37 - loss: 11.6967 - acc: 0.2479
 38/633 [>.............................] - ETA: 5:35 - loss: 11.7137 - acc: 0.2475
 39/633 [>.............................] - ETA: 5:33 - loss: 11.6393 - acc: 0.2528
 40/633 [>.............................] - ETA: 5:31 - loss: 11.6380 - acc: 0.2535
 41/633 [>.............................] - ETA: 5:30 - loss: 11.6520 - acc: 0.2532
 42/633 [>.............................] - ETA: 5:28 - loss: 11.6654 - acc: 0.2530
 43/633 [=>............................] - ETA: 5:26 - loss: 11.6343 - acc: 0.2555
 44/633 [=>............................] - ETA: 5:24 - loss: 11.6961 - acc: 0.2521
 45/633 [=>............................] - ETA: 5:22 - loss: 11.6461 - acc: 0.2557
 46/633 [=>............................] - ETA: 5:19 - loss: 11.6748 - acc: 0.2544
 47/633 [=>............................] - ETA: 5:18 - loss: 11.7104 - acc: 0.2527
 48/633 [=>............................] - ETA: 5:17 - loss: 11.7341 - acc: 0.2516
 49/633 [=>............................] - ETA: 5:15 - loss: 11.7670 - acc: 0.2500
 50/633 [=>............................] - ETA: 5:14 - loss: 11.7256 - acc: 0.2530
 51/633 [=>............................] - ETA: 5:13 - loss: 11.7055 - acc: 0.2546
 52/633 [=>............................] - ETA: 5:11 - loss: 11.6669 - acc: 0.2574
 53/633 [=>............................] - ETA: 5:10 - loss: 11.7152 - acc: 0.2547
 54/633 [=>............................] - ETA: 5:08 - loss: 11.7058 - acc: 0.2556
 55/633 [=>............................] - ETA: 5:07 - loss: 11.6693 - acc: 0.2582
 56/633 [=>............................] - ETA: 5:06 - loss: 11.6835 - acc: 0.2577
 57/633 [=>............................] - ETA: 5:05 - loss: 11.7039 - acc: 0.2567
 58/633 [=>............................] - ETA: 5:04 - loss: 11.7474 - acc: 0.2543
 59/633 [=>............................] - ETA: 5:03 - loss: 11.7959 - acc: 0.2516
 60/633 [=>............................] - ETA: 5:02 - loss: 11.8176 - acc: 0.2505
 61/633 [=>............................] - ETA: 5:01 - loss: 11.7477 - acc: 0.2551multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/jake_miller/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py", line 401, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File "/home/jake_miller/final/nlp-final-project/utils.py", line 460, in __getitem__
    batch_y_oh[np.arange(self.batch_size), batch_y] = 1
IndexError: shape mismatch: indexing arrays could not be broadcast together with shapes (128,) (65,) 
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "cnn_experiment.py", line 82, in <module>
    run_model()
  File "cnn_experiment.py", line 70, in run_model
    use_multiprocessing=True, shuffle=True)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py", line 181, in fit_generator
    generator_output = next(output_generator)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py", line 601, in get
    six.reraise(*sys.exc_info())
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/six.py", line 693, in reraise
    raise value
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py", line 595, in get
    inputs = self.queue.get(block=True).get()
  File "/home/jake_miller/anaconda3/lib/python3.6/multiprocessing/pool.py", line 644, in get
    raise self._value
IndexError: shape mismatch: indexing arrays could not be broadcast together with shapes (128,) (65,) 
2019-04-03 14:53:26.769855: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-04-03 14:53:26.771384: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Loading corpus from /home/jake_miller/final/nlp-final-project/data
Begin corpus post-processing ...
Splitting corpus into training and test ...
Creating vocabulary from training set ...
Found 8379 unique words.
Building initial embedding matrix ...
(8381, 300)
loading pretrained vectors from glove.6B.300d.txt
/home/jake_miller/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Epoch 1/50
Traceback (most recent call last):
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1322, in _do_call
    return fn(*args)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1305, in _run_fn
    self._extend_graph()
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1340, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: lstm_0/CudnnRNN = CudnnRNN[T=DT_FLOAT, direction="unidirectional", dropout=0, input_mode="linear_input", is_training=true, rnn_mode="lstm", seed=87654321, seed2=0](lstm_0/transpose, lstm_0/ExpandDims_1, lstm_0/ExpandDims_2, lstm_0/concat_1)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "lstmsoft_experiment.py", line 78, in <module>
    run_model()
  File "lstmsoft_experiment.py", line 66, in run_model
    use_multiprocessing=True, shuffle=True)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py", line 217, in fit_generator
    class_weight=class_weight)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 1217, in train_on_batch
    outputs = self.train_function(ins)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2697, in __call__
    if hasattr(get_session(), '_make_callable_from_options'):
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 199, in get_session
    [tf.is_variable_initialized(v) for v in candidate_vars])
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 900, in run
    run_metadata_ptr)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1316, in _do_run
    run_metadata)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: lstm_0/CudnnRNN = CudnnRNN[T=DT_FLOAT, direction="unidirectional", dropout=0, input_mode="linear_input", is_training=true, rnn_mode="lstm", seed=87654321, seed2=0](lstm_0/transpose, lstm_0/ExpandDims_1, lstm_0/ExpandDims_2, lstm_0/concat_1)]]

Caused by op 'lstm_0/CudnnRNN', defined at:
  File "lstmsoft_experiment.py", line 78, in <module>
    run_model()
  File "lstmsoft_experiment.py", line 49, in run_model
    stateful = False, bidirectional = False, trainable_embed = False)
  File "/home/jake_miller/final/nlp-final-project/models.py", line 75, in __init__
    bidirectional = bidirectional)
  File "/home/jake_miller/final/nlp-final-project/models.py", line 34, in layered_LSTM
    name = "lstm_" + suffix + str(i))(h_in_)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py", line 532, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py", line 457, in __call__
    output = self.call(inputs, **kwargs)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py", line 90, in call
    output, states = self._process_batch(inputs, initial_state)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py", line 517, in _process_batch
    is_training=True)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py", line 1544, in __call__
    input_data, input_h, input_c, params, is_training=is_training)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py", line 1435, in __call__
    seed=self._seed)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py", line 922, in _cudnn_rnn
    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py", line 115, in cudnn_rnn
    is_training=is_training, name=name)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3414, in create_op
    op_def=op_def)
  File "/home/jake_miller/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: lstm_0/CudnnRNN = CudnnRNN[T=DT_FLOAT, direction="unidirectional", dropout=0, input_mode="linear_input", is_training=true, rnn_mode="lstm", seed=87654321, seed2=0](lstm_0/transpose, lstm_0/ExpandDims_1, lstm_0/ExpandDims_2, lstm_0/concat_1)]]

