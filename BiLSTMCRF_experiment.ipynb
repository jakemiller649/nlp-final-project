{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "import models #_gpu as models\n",
    "import numpy as np\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger # maybe more\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kumar_model(it_no):\n",
    "\n",
    "\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 10 # it seemed to converge by this point anyway\n",
    "\n",
    "    # choose hyperparameters\n",
    "    #num_layers = np.random.randint(1,5) # lstm layers\n",
    "    #hidden_state_size = np.random.randint(100,400)\n",
    "    #dropout_rate = round(np.random.uniform(0,1,size=None), 3)\n",
    "    #embed_vec = np.random.choice(['glove200', 'glove300', 'numberbatch'])\n",
    "    #sequence_length = 5\n",
    "    bidirectional = True\n",
    "    stateful = False\n",
    "    trainable_embed = True\n",
    "    \n",
    "    num_layers = 1\n",
    "    hidden_state_size = 300\n",
    "    dropout_rate = 0.2\n",
    "    embed_vec = 'glove300'\n",
    "    sequence_length = 7\n",
    "\n",
    "    ## start the timer\n",
    "    start = time()\n",
    "\n",
    "    # load the corpus\n",
    "    corpus = utils.AMI_Corpus(seed = 75, embed_vec = embed_vec)\n",
    "\n",
    "    bi_lstm = models.BiLSTMCRF(corpus,\n",
    "                               batch_size = BATCH_SIZE,\n",
    "                               sequence_length = sequence_length,\n",
    "                               num_layers = num_layers,\n",
    "                               dropout_rate = dropout_rate,\n",
    "                               hidden_state_size = hidden_state_size,\n",
    "                               stateful = stateful, bidirectional = bidirectional, \n",
    "                               trainable_embed = trainable_embed)\n",
    "\n",
    "    bi_lstm.compile()\n",
    "\n",
    "    ug_train = utils.UtteranceGenerator(corpus, \"train\", batch_size = BATCH_SIZE, sequence_length = sequence_length, conv = True, kumar = True)\n",
    "    ug_val = utils.UtteranceGenerator(corpus, \"val\", batch_size = BATCH_SIZE, sequence_length = sequence_length, conv = True, kumar = True)\n",
    "\n",
    "    # create keras callbacks\n",
    "    es = EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "\n",
    "    #right_now = datetime.now().isoformat() # timestamp\n",
    "    csv_logger = CSVLogger('logs/kumar_history_' + str(it_no) + \".csv\") # log epochs in case I want to look back later\n",
    "\n",
    "    # note to self, maybe change validation_steps and validation_freq\n",
    "    history = bi_lstm.model.fit_generator(ug_train, epochs=EPOCHS, verbose=1, callbacks=[es, csv_logger],\n",
    "                                          validation_data=ug_val)\n",
    "\n",
    "    results = {\"num_layers\":num_layers, \"hidden_state_size\":hidden_state_size,\"dropout_rate\":dropout_rate, \"sequence_length\":sequence_length,\"embed_vec\":embed_vec, \"acc\":history.history['crf_viterbi_accuracy'][-5:],\n",
    "               \"val_acc\":history.history['val_crf_viterbi_accuracy'][-5:], \"loss\":history.history['loss'][-5:],\n",
    "               \"val_loss\":history.history['val_loss'][-5:], \"time\":time() - start,\"trainable_embed\":trainable_embed,\n",
    "               \"stateful\":stateful, \"bidirectional\":bidirectional}\n",
    "    \n",
    "    results = {str(k):str(v) for k,v in results.items()}\n",
    "\n",
    "    with open(\"logs/kumar_params_\" + str(it_no) + \".json\", \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "    \n",
    "    print(\"-------------------\")\n",
    "\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus from /home/jake_miller/final/nlp-final-project/data\n",
      "Begin corpus post-processing ...\n",
      "Splitting corpus into training and test ...\n",
      "Creating vocabulary from training set ...\n",
      "Found 8435 unique words.\n",
      "Building initial embedding matrix ...\n",
      "(8437, 300)\n",
      "loading pretrained vectors from numberbatch-en.txt\n",
      "Epoch 1/10\n",
      "311/311 [==============================] - 129s 414ms/step - loss: 2.0635 - crf_viterbi_accuracy: 0.2822 - val_loss: 1.8820 - val_crf_viterbi_accuracy: 0.3306\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 114s 367ms/step - loss: 1.7461 - crf_viterbi_accuracy: 0.3754 - val_loss: 1.6646 - val_crf_viterbi_accuracy: 0.4221\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 114s 366ms/step - loss: 1.4837 - crf_viterbi_accuracy: 0.4664 - val_loss: 1.3633 - val_crf_viterbi_accuracy: 0.5224\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 114s 368ms/step - loss: 1.3235 - crf_viterbi_accuracy: 0.5260 - val_loss: 1.2620 - val_crf_viterbi_accuracy: 0.5499\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 114s 367ms/step - loss: 1.2368 - crf_viterbi_accuracy: 0.5506 - val_loss: 1.2041 - val_crf_viterbi_accuracy: 0.5622\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 114s 367ms/step - loss: 1.1679 - crf_viterbi_accuracy: 0.5671 - val_loss: 1.1640 - val_crf_viterbi_accuracy: 0.5738\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 114s 367ms/step - loss: 1.1189 - crf_viterbi_accuracy: 0.5770 - val_loss: 1.1191 - val_crf_viterbi_accuracy: 0.5844\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 114s 366ms/step - loss: 1.0723 - crf_viterbi_accuracy: 0.5884 - val_loss: 1.0852 - val_crf_viterbi_accuracy: 0.5873\n",
      "Epoch 9/10\n",
      "311/311 [==============================] - 114s 368ms/step - loss: 1.0293 - crf_viterbi_accuracy: 0.5960 - val_loss: 1.0469 - val_crf_viterbi_accuracy: 0.5926\n",
      "Epoch 10/10\n",
      "311/311 [==============================] - 114s 368ms/step - loss: 0.9943 - crf_viterbi_accuracy: 0.6005 - val_loss: 1.0407 - val_crf_viterbi_accuracy: 0.5887\n",
      "-------------------\n",
      "Loading corpus from /home/jake_miller/final/nlp-final-project/data\n",
      "Begin corpus post-processing ...\n",
      "Splitting corpus into training and test ...\n",
      "Creating vocabulary from training set ...\n",
      "Found 8435 unique words.\n",
      "Building initial embedding matrix ...\n",
      "(8437, 300)\n",
      "loading pretrained vectors from glove.6B.300d.txt\n",
      "Epoch 1/10\n",
      "311/311 [==============================] - 99s 319ms/step - loss: 1.8826 - crf_viterbi_accuracy: 0.3369 - val_loss: 1.5655 - val_crf_viterbi_accuracy: 0.4470\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 83s 268ms/step - loss: 1.3998 - crf_viterbi_accuracy: 0.5148 - val_loss: 1.2825 - val_crf_viterbi_accuracy: 0.5617\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 83s 267ms/step - loss: 1.2318 - crf_viterbi_accuracy: 0.5687 - val_loss: 1.1762 - val_crf_viterbi_accuracy: 0.5874\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 83s 267ms/step - loss: 1.1543 - crf_viterbi_accuracy: 0.5827 - val_loss: 1.1335 - val_crf_viterbi_accuracy: 0.5946\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 83s 267ms/step - loss: 1.0992 - crf_viterbi_accuracy: 0.5920 - val_loss: 1.0996 - val_crf_viterbi_accuracy: 0.5906\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 83s 267ms/step - loss: 1.0470 - crf_viterbi_accuracy: 0.5995 - val_loss: 1.0459 - val_crf_viterbi_accuracy: 0.6039\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 83s 268ms/step - loss: 1.0024 - crf_viterbi_accuracy: 0.6094 - val_loss: 1.0169 - val_crf_viterbi_accuracy: 0.6074\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 83s 267ms/step - loss: 0.9584 - crf_viterbi_accuracy: 0.6181 - val_loss: 0.9708 - val_crf_viterbi_accuracy: 0.6143\n",
      "Epoch 9/10\n",
      "311/311 [==============================] - 83s 267ms/step - loss: 0.9197 - crf_viterbi_accuracy: 0.6270 - val_loss: 0.9375 - val_crf_viterbi_accuracy: 0.6203\n",
      "Epoch 10/10\n",
      "311/311 [==============================] - 83s 268ms/step - loss: 0.8795 - crf_viterbi_accuracy: 0.6355 - val_loss: 0.9286 - val_crf_viterbi_accuracy: 0.6199\n",
      "-------------------\n",
      "Loading corpus from /home/jake_miller/final/nlp-final-project/data\n",
      "Begin corpus post-processing ...\n",
      "Splitting corpus into training and test ...\n",
      "Creating vocabulary from training set ...\n",
      "Found 8435 unique words.\n",
      "Building initial embedding matrix ...\n",
      "(8437, 300)\n",
      "loading pretrained vectors from glove.6B.300d.txt\n",
      "Epoch 1/10\n",
      "311/311 [==============================] - 83s 268ms/step - loss: 2.0267 - crf_viterbi_accuracy: 0.2824 - val_loss: 1.7700 - val_crf_viterbi_accuracy: 0.3569\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 65s 210ms/step - loss: 1.5533 - crf_viterbi_accuracy: 0.4154 - val_loss: 1.3404 - val_crf_viterbi_accuracy: 0.5121\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 65s 210ms/step - loss: 1.2899 - crf_viterbi_accuracy: 0.5265 - val_loss: 1.2027 - val_crf_viterbi_accuracy: 0.5626\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 65s 210ms/step - loss: 1.2026 - crf_viterbi_accuracy: 0.5515 - val_loss: 1.1597 - val_crf_viterbi_accuracy: 0.5638\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 66s 211ms/step - loss: 1.1634 - crf_viterbi_accuracy: 0.5610 - val_loss: 1.1426 - val_crf_viterbi_accuracy: 0.5738\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 65s 210ms/step - loss: 1.1254 - crf_viterbi_accuracy: 0.5673 - val_loss: 1.1030 - val_crf_viterbi_accuracy: 0.5810\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 65s 210ms/step - loss: 1.1003 - crf_viterbi_accuracy: 0.5720 - val_loss: 1.0779 - val_crf_viterbi_accuracy: 0.5827\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 65s 210ms/step - loss: 1.0922 - crf_viterbi_accuracy: 0.5689 - val_loss: 1.0522 - val_crf_viterbi_accuracy: 0.5861\n",
      "Epoch 9/10\n",
      "311/311 [==============================] - 66s 211ms/step - loss: 1.0439 - crf_viterbi_accuracy: 0.5788 - val_loss: 1.0274 - val_crf_viterbi_accuracy: 0.5889\n",
      "Epoch 10/10\n",
      "311/311 [==============================] - 65s 210ms/step - loss: 1.0206 - crf_viterbi_accuracy: 0.5811 - val_loss: 1.0003 - val_crf_viterbi_accuracy: 0.5905\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "reload(utils)\n",
    "reload(models)\n",
    "for i in range(2,5):\n",
    "    reults = run_kumar_model(it_no = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, sequence = 6 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus from /home/jake_miller/final/nlp-final-project/data\n",
      "Begin corpus post-processing ...\n",
      "Splitting corpus into training and test ...\n",
      "Creating vocabulary from training set ...\n",
      "Found 8435 unique words.\n",
      "Building initial embedding matrix ...\n",
      "(8437, 300)\n",
      "loading pretrained vectors from glove.6B.300d.txt\n",
      "Epoch 1/10\n",
      "311/311 [==============================] - 67s 217ms/step - loss: 1.5900 - crf_viterbi_accuracy: 0.4621 - val_loss: 1.2778 - val_crf_viterbi_accuracy: 0.5694\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 47s 151ms/step - loss: 1.2235 - crf_viterbi_accuracy: 0.5730 - val_loss: 1.1588 - val_crf_viterbi_accuracy: 0.5905\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 47s 152ms/step - loss: 1.1103 - crf_viterbi_accuracy: 0.5947 - val_loss: 1.0639 - val_crf_viterbi_accuracy: 0.6094\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 47s 152ms/step - loss: 1.0131 - crf_viterbi_accuracy: 0.6173 - val_loss: 0.9926 - val_crf_viterbi_accuracy: 0.6200\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 47s 151ms/step - loss: 0.9315 - crf_viterbi_accuracy: 0.6382 - val_loss: 0.9552 - val_crf_viterbi_accuracy: 0.6272\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 47s 152ms/step - loss: 0.8670 - crf_viterbi_accuracy: 0.6526 - val_loss: 0.8998 - val_crf_viterbi_accuracy: 0.6439\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 47s 151ms/step - loss: 0.8187 - crf_viterbi_accuracy: 0.6626 - val_loss: 0.8696 - val_crf_viterbi_accuracy: 0.6454\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 47s 152ms/step - loss: 0.7790 - crf_viterbi_accuracy: 0.6726 - val_loss: 0.8442 - val_crf_viterbi_accuracy: 0.6517\n",
      "Epoch 9/10\n",
      "311/311 [==============================] - 47s 151ms/step - loss: 0.7455 - crf_viterbi_accuracy: 0.6792 - val_loss: 0.8455 - val_crf_viterbi_accuracy: 0.6451\n",
      "Epoch 10/10\n",
      "311/311 [==============================] - 47s 151ms/step - loss: 0.7145 - crf_viterbi_accuracy: 0.6869 - val_loss: 0.8266 - val_crf_viterbi_accuracy: 0.6495\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "reults = run_kumar_model(it_no = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus from /home/jake_miller/final/nlp-final-project/data\n",
      "Begin corpus post-processing ...\n",
      "Splitting corpus into training and test ...\n",
      "Creating vocabulary from training set ...\n",
      "Found 8435 unique words.\n",
      "Building initial embedding matrix ...\n",
      "(8437, 300)\n",
      "loading pretrained vectors from glove.6B.300d.txt\n",
      "Epoch 1/10\n",
      "311/311 [==============================] - 78s 251ms/step - loss: 1.5766 - crf_viterbi_accuracy: 0.4652 - val_loss: 1.2613 - val_crf_viterbi_accuracy: 0.5749\n",
      "Epoch 2/10\n",
      "311/311 [==============================] - 55s 176ms/step - loss: 1.2159 - crf_viterbi_accuracy: 0.5747 - val_loss: 1.1556 - val_crf_viterbi_accuracy: 0.5907\n",
      "Epoch 3/10\n",
      "311/311 [==============================] - 55s 177ms/step - loss: 1.1059 - crf_viterbi_accuracy: 0.5983 - val_loss: 1.0585 - val_crf_viterbi_accuracy: 0.6132\n",
      "Epoch 4/10\n",
      "311/311 [==============================] - 55s 176ms/step - loss: 1.0145 - crf_viterbi_accuracy: 0.6213 - val_loss: 0.9935 - val_crf_viterbi_accuracy: 0.6274\n",
      "Epoch 5/10\n",
      "311/311 [==============================] - 55s 176ms/step - loss: 0.9406 - crf_viterbi_accuracy: 0.6403 - val_loss: 0.9631 - val_crf_viterbi_accuracy: 0.6302\n",
      "Epoch 6/10\n",
      "311/311 [==============================] - 55s 176ms/step - loss: 0.8813 - crf_viterbi_accuracy: 0.6545 - val_loss: 0.9117 - val_crf_viterbi_accuracy: 0.6465\n",
      "Epoch 7/10\n",
      "311/311 [==============================] - 55s 177ms/step - loss: 0.8358 - crf_viterbi_accuracy: 0.6650 - val_loss: 0.8817 - val_crf_viterbi_accuracy: 0.6500\n",
      "Epoch 8/10\n",
      "311/311 [==============================] - 55s 177ms/step - loss: 0.7973 - crf_viterbi_accuracy: 0.6756 - val_loss: 0.8583 - val_crf_viterbi_accuracy: 0.6543\n",
      "Epoch 9/10\n",
      "311/311 [==============================] - 55s 176ms/step - loss: 0.7655 - crf_viterbi_accuracy: 0.6811 - val_loss: 0.8602 - val_crf_viterbi_accuracy: 0.6492\n",
      "Epoch 10/10\n",
      "311/311 [==============================] - 55s 177ms/step - loss: 0.7357 - crf_viterbi_accuracy: 0.6887 - val_loss: 0.8432 - val_crf_viterbi_accuracy: 0.6533\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# now, for sequence length 7 ...\n",
    "reults = run_kumar_model(it_no = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
